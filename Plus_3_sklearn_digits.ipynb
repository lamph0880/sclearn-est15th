{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Scikit-Learn 내장 데이터셋: Optical Recognition of Handwritten Digits Dataset\n",
                "\n",
                "이 노트북은 scikit-learn에 내장된 `load_digits` 함수를 사용하여 손글씨 숫자 데이터셋을 분석하고 분류하는 과정을 다룹니다.\n",
                "\n",
                "### 데이터셋 정보\n",
                "- **데이터 구성**: 1,797개의 8x8 픽셀 이미지 데이터\n",
                "- **클래스**: 0부터 9까지의 숫자 (총 10개 클래스)\n",
                "- **특성(Features)**: 각 픽셀의 밝기를 나타내는 64개(8x8)의 정수 값 (0~16 범위)\n",
                "- **목표**: 8x8 이미지를 입력받아 해당 이미지가 어떤 숫자인지 예측\n",
                "\n",
                "이 데이터셋은 MNIST 데이터셋의 축소판 버전으로, 하드웨어 성능의 제약 없이 머신러닝 알고리즘을 테스트하기에 적합합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.datasets import load_digits\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# 시각화 설정\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette(\"viridis\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 데이터 로드 및 탐색적 데이터 분석 (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 데이터 로드\n",
                "digits = load_digits()\n",
                "X = digits.data\n",
                "y = digits.target\n",
                "\n",
                "print(f\"데이터 크기: {X.shape}\")\n",
                "print(f\"타겟 클래스: {np.unique(y)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 샘플 데이터 시각화\n",
                "plt.figure(figsize=(10, 4))\n",
                "for index, (image, label) in enumerate(zip(digits.images[:10], digits.target[:10])):\n",
                "    plt.subplot(2, 5, index + 1)\n",
                "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
                "    plt.title(f'Label: {label}')\n",
                "    plt.axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 클래스 분포 확인\n",
                "plt.figure(figsize=(8, 5))\n",
                "sns.countplot(x=y)\n",
                "plt.title('Target Class Distribution')\n",
                "plt.xlabel('Digit Class')\n",
                "plt.ylabel('Count')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 데이터 전처리 및 특성 엔지니어링"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 데이터 분할 (학습용 80%, 테스트용 20%)\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# 데이터 스케일링\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "print(f\"학습 데이터 크기: {X_train.shape}\")\n",
                "print(f\"테스트 데이터 크기: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 모델링 (6가지 모델 평가)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "\n",
                "# 베이스라인 모델 성능 측정을 위한 딕셔너리\n",
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
                "    'SVC': SVC(),\n",
                "    'Random Forest': RandomForestClassifier(random_state=42),\n",
                "    'KNN': KNeighborsClassifier(),\n",
                "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
                "    'Extra Trees': ExtraTreesClassifier(random_state=42)\n",
                "}\n",
                "\n",
                "model_results = {}\n",
                "\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train_scaled, y_train)\n",
                "    y_pred = model.predict(X_test_scaled)\n",
                "    acc = accuracy_score(y_test, y_pred)\n",
                "    model_results[name] = acc\n",
                "    print(f\"{name} Accuracy: {acc:.4f}\")\n",
                "\n",
                "# 성능 기준 정렬 후 상위 4개 모델 선정\n",
                "sorted_models = sorted(model_results.items(), key=lambda x: x[1], reverse=True)\n",
                "top_4_model_names = [m[0] for m in sorted_models[:4]]\n",
                "print(f\"\\n상위 4개 모델: {top_4_model_names}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 하이퍼파라메터 튜닝 및 앙상블 모델"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import VotingClassifier\n",
                "\n",
                "# 튜닝할 파라미터 정의 (예시)\n",
                "param_grids = {\n",
                "    'SVC': {'C': [0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1], 'probability': [True]},\n",
                "    'Random Forest': {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n",
                "    'KNN': {'n_neighbors': [3, 5, 7]},\n",
                "    'Extra Trees': {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n",
                "    'Logistic Regression': {'C': [0.1, 1, 10]},\n",
                "    'Gradient Boosting': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}\n",
                "}\n",
                "\n",
                "best_estimators = []\n",
                "\n",
                "for name in top_4_model_names:\n",
                "    print(f\"{name} 튜닝 중...\")\n",
                "    grid = GridSearchCV(models[name], param_grids[name], cv=3, n_jobs=-1)\n",
                "    grid.fit(X_train_scaled, y_train)\n",
                "    best_estimators.append((name, grid.best_estimator_))\n",
                "    print(f\"{name} 최적 파라미터: {grid.best_params_}\")\n",
                "\n",
                "# 소프트 보팅 앙상블 생성\n",
                "ensemble_model = VotingClassifier(estimators=best_estimators, voting='soft')\n",
                "ensemble_model.fit(X_train_scaled, y_train)\n",
                "\n",
                "print(\"\\n앙상블 모델 학습 완료\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 최종 모델 평가"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred_final = ensemble_model.predict(X_test_scaled)\n",
                "\n",
                "print(\"### 앙상블 모델 최종 성능 ###\")\n",
                "print(f\"최종 정확도 (Accuracy): {accuracy_score(y_test, y_pred_final):.4f}\")\n",
                "print(\"\\n--- Classification Report ---\")\n",
                "print(classification_report(y_test, y_pred_final))\n",
                "\n",
                "# 혼동 행렬 시각화\n",
                "plt.figure(figsize=(10, 8))\n",
                "cm = confusion_matrix(y_test, y_pred_final)\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
                "plt.title('Final Ensemble Model Confusion Matrix')\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "DS",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
